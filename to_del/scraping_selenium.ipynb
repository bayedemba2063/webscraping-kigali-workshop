{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping practice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static websites with Selenium\n",
    "1. Data model with Pydantic (refresh)\n",
    "2. Get robot.txt and create exclusion protocol for other calls [webdriver subclass and wrapper for driver.get()]\n",
    "3. Get the structure for directories (refresh)\n",
    "4. Scrape from catalogue\n",
    "5. Follow pagination\n",
    "6. Save data to CSV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melcom (Ghana)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Product(BaseModel):\n",
    "    link: str\n",
    "    source: str\n",
    "    category: str = None\n",
    "    subcategory: str = None\n",
    "    subsubcategory: str = None\n",
    "    name: str = None\n",
    "    brand: str = None\n",
    "    uid: str = None\n",
    "    price: float\n",
    "    regular_price: float = None\n",
    "    currency: str\n",
    "    in_stock: str = None\n",
    "    description: str = None\n",
    "    date: str = date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "class Melcom(Product):\n",
    "    source: str = \"Melcom\"\n",
    "    currency: str = \"GHS\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and parse robots.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.robotparser import RobotFileParser\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "melcom_root = \"https://melcom.com/\"\n",
    "robots_melcom = RobotFileParser(melcom_root + \"robots.txt\")\n",
    "robots_melcom.read()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We setup the browser and try to get the homepage, just to check it works.  \n",
    "When we create the driver object we set up an implicit wait [https://www.selenium.dev/documentation/webdriver/waits/](https://www.selenium.dev/documentation/webdriver/waits/). You can also use explicit waits, but it is not suggested to mix the two types. In my experience, implicit waits are easier to manage. However, explicit waits can solve more complicated and specific issues. Each case may have a different optimal solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "opts = Options()\n",
    "\n",
    "# Windows and Linux options for setting the paths, uncomment the right one for your Operating system\n",
    "# And comment the other one\n",
    "\n",
    "#chromium_path = \"C:\\\\Users\\\\domin\\\\chrome-win\\\\chrome.exe\"  # Windows path Chromium\n",
    "chromium_path = \"/snap/chromium/current/usr/lib/chromium-browser/chrome\"  # Linux Path Chromium\n",
    "opts.binary_location = chromium_path\n",
    "opts.add_argument(\"user-agent=Webscraping Capacity Building 1.0\")\n",
    "#chromedriver_path = Service(\"C:\\\\Users\\\\domin\\\\chromedriver_win32\\\\chromedriver.exe\")  # Windows path Chromedriver\n",
    "chromedriver_path = Service(executable_path=\"/snap/chromium/current/usr/lib/chromium-browser/chromedriver\")  # Linux Path Chromedriver\n",
    "driver = webdriver.Chrome(service=chromedriver_path, options=opts)\n",
    "driver.implicitly_wait(30)  # The driver will wait up to 30 seconds each time we ask to perform an action or get an element\n",
    "driver.get(melcom_root)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have an open browser, let's check we have correcly set the User Agent and which information we are sending to the website. We use one of the websites (there are many others) that displays that for us: [https://www.whatismybrowser.com/detect/](https://www.whatismybrowser.com/detect/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the User Agent:\n",
    "driver.get(\"https://www.whatismybrowser.com/detect/what-is-my-user-agent/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all the headers we send\n",
    "driver.get(\"https://www.whatismybrowser.com/detect/what-http-headers-is-my-browser-sending\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we are only sending the User Agent and not the email like we were doing with Requests. In order to further modify the headers for the HTTP requests we make we should use a different library, for instance [Selenium Wire](https://pypi.org/project/selenium-wire/), in order to get more control on the requests we make. Or - simpler - we could include our email inside the User Agent. Since Selenium Wire releases sometimes lags several months behind Selenium, I would suggest this second options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We close the driver and rebuild again with an updated User Agent\n",
    "driver.quit()\n",
    "\n",
    "opts.add_argument(\"user-agent=Webscraping Capacity Building 1.0/mail: luigi.palumbo@unitus.it\")\n",
    "driver = webdriver.Chrome(service=chromedriver_path, options=opts)\n",
    "driver.implicitly_wait(30)  # The driver will wait up to 30 seconds each time we ask to perform an action or get an element\n",
    "driver.get(\"https://www.whatismybrowser.com/detect/what-http-headers-is-my-browser-sending\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to check the User Agent you are sending is to use JavaScript, and simply execute a JavaScript command in the browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Webscraping Capacity Building 1.0/mail: luigi.palumbo@unitus.it'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.execute_script('return navigator.userAgent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always remember to close the browser!\n",
    "driver.quit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Safe Get method\n",
    "\n",
    "This time we take a different approach to make sure our requests respect the website robots.txt. We create a subclass from the webdriver.Chrome class, and we add a new method - safe_get() - which also takes as an argument the parsed robots.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafeChrome(webdriver.Chrome):\n",
    "    def safe_get(self, url: str, robots: RobotFileParser):\n",
    "        \"\"\"Load a webpage in the current browser session\n",
    "        if allowed by robots.txt for the specific website\n",
    "        \"\"\"\n",
    "        if robots.can_fetch(self.execute_script('return navigator.userAgent'), url):\n",
    "            self.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = SafeChrome(service=chromedriver_path, options=opts)\n",
    "driver.implicitly_wait(30)  # The driver will wait up to 30 seconds each time we ask to perform an action or get an element\n",
    "driver.safe_get(melcom_root, robots_melcom)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also make a double check on a forbidden URL from another website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrefour_root = \"https://www.carrefour.tn/\"\n",
    "robots_carrefour = RobotFileParser(carrefour_root + \"robots.txt\")\n",
    "robots_carrefour.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first call should work, as it is the homepage\n",
    "driver.safe_get(\"https://www.carrefour.tn/\", robots_carrefour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second one should not, as it is in the Disallow list for all User Agents\n",
    "driver.safe_get(\"https://www.carrefour.tn/review/\", robots_carrefour)  # the browser does not go to this new page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But regular get request would go thru...\n",
    "driver.get(\"https://www.carrefour.tn/review/\")  # and find a broken page, in this case"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting content from the browser\n",
    "\n",
    "Selenium has advanced capabilities to extract information from the webpage selecting just specific elements. This is very important in case different elements load at different times (also see Explicit Waits above if this case is relevant for you). However, in many instances it is preferrable to completely extract the full HTML content from the webpage and parse it with BeautifulSoup. This enables you to only use a single tool and methodology for parsing content, independently whether you are scraping via Requests or Selenium, and ultimately makes your work easier to maintain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We go back to Melcom homepage\n",
    "driver.safe_get(melcom_root, robots_melcom)\n",
    "\n",
    "# There are two alternative methods to extract the HTML, and they do not always behave the same way.\n",
    "homepage = driver.execute_script(\"return document.body.innerHTML;\")\n",
    "\n",
    "# Alternative, uncomment to run\n",
    "#homepage = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the HTML with BeautifulSoup\n",
    "homepage = BeautifulSoup(homepage, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Television & Audio',\n",
       "  'link': 'https://melcom.com/categories/electronics-appliances/television-audio.html'},\n",
       " {'name': 'Refrigerators & Freezers',\n",
       "  'link': 'https://melcom.com/categories/electronics-appliances/refrigerators-freezers.html'},\n",
       " {'name': 'Washing Machines',\n",
       "  'link': 'https://melcom.com/categories/electronics-appliances/washing-machines.html'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the categories links\n",
    "categories = [\n",
    "    {\"name\": item.get_text(), \"link\": item.find(\"a\").get(\"href\") }\n",
    "    for item in homepage.find(\"div\", {\"id\": \"custom.topnav\"}).find(\"ul\", {\"class\": \"mega-columns\"}).find_all(\"li\", {\"class\": \"level2\"})]\n",
    "\n",
    "categories[:3] # We display the first three categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just browsing across a couple of categories\n",
    "for cat in categories[:2]:\n",
    "    driver.safe_get(cat.get(\"link\"), robots_melcom)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = driver.execute_script(\"return document.body.innerHTML;\")\n",
    "# Parsing the HTML with BeautifulSoup\n",
    "page = BeautifulSoup(page, \"html.parser\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We grab the main data from the catalogue page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AKAI FRIDGE DOUBLE DOOR DISPLAY 520L BLACK'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Product name\n",
    "page.find(\"ol\", {\"class\": \"container-products-switch\"}).find_all(\"div\", {\"class\": \"product-item-details\"})[0].find(\"a\", {\"class\": \"product-item-link\"}).get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://melcom.com/categories/electronics-appliances/refrigerators-freezers/akai-fridge-double-door-display-520l-black.html'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Product link\n",
    "page.find(\"ol\", {\"class\": \"container-products-switch\"}).find_all(\"div\", {\"class\": \"product-item-details\"})[0].find(\"a\", {\"class\": \"product-item-link\"}).get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12999'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Price\n",
    "page.find(\"ol\", {\"class\": \"container-products-switch\"}).find_all(\"div\", {\"class\": \"product-item-details\"})[0].find(\"span\", {\"class\": \"price-wrapper\"}).get(\"data-price-amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6099'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Special price for products in offer\n",
    "page.find(\"ol\", {\"class\": \"container-products-switch\"}).find_all(\"div\", {\"class\": \"product-item-details\"})[2].find(\"span\", {\"class\": \"special-price\"}).find(\"span\", {\"class\": \"price-wrapper\"}).get(\"data-price-amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7899'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regular price for products in offer\n",
    "page.find(\"ol\", {\"class\": \"container-products-switch\"}).find_all(\"div\", {\"class\": \"product-item-details\"})[2].find(\"span\", {\"class\": \"old-price\"}).find(\"span\", {\"class\": \"price-wrapper\"}).get(\"data-price-amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'AKAI FRIDGE DOUBLE DOOR DISPLAY 520L BLACK',\n",
       "  'link': 'https://melcom.com/categories/electronics-appliances/refrigerators-freezers/akai-fridge-double-door-display-520l-black.html',\n",
       "  'price': '12999'},\n",
       " {'name': 'AKAI FRIDGE SINGLE DOOR DISPLAY 289L BLACK',\n",
       "  'link': 'https://melcom.com/categories/electronics-appliances/refrigerators-freezers/akai-fridge-single-door-display-289l-black.html',\n",
       "  'price': '8499'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get all the products\n",
    "products = [\n",
    "    {\n",
    "    \"name\": item.find(\"a\", {\"class\": \"product-item-link\"}).get_text().strip(),\n",
    "    \"link\": item.find(\"a\", {\"class\": \"product-item-link\"}).get(\"href\"),\n",
    "    \"price\": item.find(\"span\", {\"class\": \"price-wrapper\"}).get(\"data-price-amount\")\n",
    "    }\n",
    "    for item in page.find(\"ol\", {\"class\": \"container-products-switch\"}).find_all(\"div\", {\"class\": \"product-item-details\"})\n",
    "]\n",
    "\n",
    "# We display just two\n",
    "products[:2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pagination\n",
    "\n",
    "We need to identify the way this website gives us the link for the new page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://melcom.com/categories/electronics-appliances/refrigerators-freezers.html?p=2'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_page = page.find(\"ul\", {\"class\": \"pages-items\"}).find(\"a\",{\"class\": \"next\"}).get(\"href\")\n",
    "\n",
    "next_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go the the last page and check what comes out if we look for the next one\n",
    "\n",
    "driver.safe_get(\"https://melcom.com/categories/electronics-appliances/refrigerators-freezers.html?p=3\", robots_melcom)\n",
    "\n",
    "page = driver.execute_script(\"return document.body.innerHTML;\")\n",
    "# Parsing the HTML with BeautifulSoup\n",
    "page = BeautifulSoup(page, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.find(\"ul\", {\"class\": \"pages-items\"}).find(\"a\",{\"class\": \"next\"}) is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m page\u001b[39m.\u001b[39;49mfind(\u001b[39m\"\u001b[39;49m\u001b[39mul\u001b[39;49m\u001b[39m\"\u001b[39;49m, {\u001b[39m\"\u001b[39;49m\u001b[39mclass\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mpages-items\u001b[39;49m\u001b[39m\"\u001b[39;49m})\u001b[39m.\u001b[39;49mfind(\u001b[39m\"\u001b[39;49m\u001b[39ma\u001b[39;49m\u001b[39m\"\u001b[39;49m,{\u001b[39m\"\u001b[39;49m\u001b[39mclass\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mnext\u001b[39;49m\u001b[39m\"\u001b[39;49m})\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39m\u001b[39mhref\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "page.find(\"ul\", {\"class\": \"pages-items\"}).find(\"a\",{\"class\": \"next\"}).get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need also to consider that pages without pagination does not even have an ul tag of class page-items\n",
    "driver.safe_get(\"https://melcom.com/categories/electronics-appliances/washing-machines.html\", robots_melcom)\n",
    "\n",
    "page = driver.execute_script(\"return document.body.innerHTML;\")\n",
    "# Parsing the HTML with BeautifulSoup\n",
    "page = BeautifulSoup(page, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.find(\"ul\", {\"class\": \"pages-items\"}) is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.find(\"ul\", {\"class\": \"pages-items\"}).find(\"a\",{\"class\": \"next\"}) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one of the examples where grabbing values directly from Selenium could be more linear. Or we could try to select the link in less steps (for instance, skipping the ul and directly searching for the a tag with class next).\n",
    "\n",
    "However, I believe that the additional solidity of more granular selectors is worth the additional effort and overhead of a try-except statement. This again is an opinion, different choices may be completely valid.\n",
    "\n",
    "Let's build a function that starts from a category link and gets data for all products in a category from the catalogue page, moving from page to page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_category(link: str, category: str, Item: BaseModel, wd: webdriver, robots: RobotFileParser, delay: float = 1) -> list:\n",
    "    \"\"\"Function to scrape a category from catalogue pages with Selenium\n",
    "    following pagination.\n",
    "    Parameters:\n",
    "        link (str): starting link for a category\n",
    "        category (str): category name\n",
    "        Item (BaseModel): class of the data object for the specific source\n",
    "        wd (webdriver): Selenium Webdriver with User-Agent properly set and safe_get() method\n",
    "        robots (RobotFileParser): Initialized robots.txt parsed object for the specific website\n",
    "        delay (float): delay in seconds between calls to prevent overloading the source and allow pages to fully render\n",
    "\n",
    "    Returns:\n",
    "        list of product with all information\n",
    "\n",
    "    \"\"\"\n",
    "    wd.safe_get(link, robots)\n",
    "    time.sleep(delay)\n",
    "    page = driver.execute_script(\"return document.body.innerHTML;\")\n",
    "    # Parsing the HTML with BeautifulSoup\n",
    "    page = BeautifulSoup(page, \"html.parser\")\n",
    "    results = []\n",
    "    for item in page.find(\"ol\", {\"class\": \"container-products-switch\"}).find_all(\"div\", {\"class\": \"product-item-details\"}):\n",
    "        product = {}\n",
    "        # Parse product information\n",
    "        product[\"name\"] = item.find(\"a\", {\"class\": \"product-item-link\"}).get_text().strip()\n",
    "        product[\"link\"] = item.find(\"a\", {\"class\": \"product-item-link\"}).get(\"href\")\n",
    "        if item.find(\"span\", {\"class\": \"old-price\"}) is not None:\n",
    "            product[\"price\"] = item.find(\"span\", {\"class\": \"special-price\"}).find(\"span\", {\"class\": \"price-wrapper\"}).get(\"data-price-amount\")\n",
    "            product[\"regular_price\"] = item.find(\"span\", {\"class\": \"old-price\"}).find(\"span\", {\"class\": \"price-wrapper\"}).get(\"data-price-amount\")\n",
    "        else:\n",
    "            product[\"price\"] = item.find(\"span\", {\"class\": \"price-wrapper\"}).get(\"data-price-amount\")\n",
    "\n",
    "        results.append(product)\n",
    "    \n",
    "    # Parse all products accodring to the data class\n",
    "    results = [Item(**res, category=category) for res in results]\n",
    "\n",
    "    # Follow pagination if exists\n",
    "    try:\n",
    "        next_page = page.find(\"ul\", {\"class\": \"pages-items\"}).find(\"a\",{\"class\": \"next\"})\n",
    "        if next_page is not None:\n",
    "            next_page = next_page.get(\"href\")\n",
    "            next_results = scrape_category(link=next_page, category=category, Item=Item, wd=wd, robots= robots, delay=delay)\n",
    "            results.extend(next_results)\n",
    "    except AttributeError as e:\n",
    "        print(e)  # This should go away in production\n",
    "        pass\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's scrape a couple of categories to test\n",
    "melcom_data = []\n",
    "\n",
    "for cat in categories[:2]:  # Limit to two categories for test\n",
    "    melcom_data.extend(scrape_category(cat.get(\"link\"), cat.get(\"name\"), Melcom, driver, robots_melcom, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always remember to close the browser!\n",
    "driver.quit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "melcom_catalog_df = pd.DataFrame([prod.dict(exclude_none=True) for prod in melcom_data])\n",
    "melcom_catalog_df.to_csv(\"melcom_catalog_{}.csv\".format(date.today().strftime(\"%Y-%m-%d\")), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>category</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>currency</th>\n",
       "      <th>date</th>\n",
       "      <th>regular_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://melcom.com/categories/electronics-appl...</td>\n",
       "      <td>Melcom</td>\n",
       "      <td>Television &amp; Audio</td>\n",
       "      <td>YAMAHA FRONT SURROUND SYSTEM BLACK YAS209</td>\n",
       "      <td>6499.0</td>\n",
       "      <td>GHS</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://melcom.com/categories/electronics-appl...</td>\n",
       "      <td>Melcom</td>\n",
       "      <td>Television &amp; Audio</td>\n",
       "      <td>YAMAHA MUSIC SYNTHESIZER MODX8 B/E</td>\n",
       "      <td>34999.0</td>\n",
       "      <td>GHS</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://melcom.com/categories/electronics-appl...</td>\n",
       "      <td>Melcom</td>\n",
       "      <td>Television &amp; Audio</td>\n",
       "      <td>YAMAHA DIGITAL KEYBOARD WITH ADAPTOR PSR-F52Y</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>GHS</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://melcom.com/categories/electronics-appl...</td>\n",
       "      <td>Melcom</td>\n",
       "      <td>Television &amp; Audio</td>\n",
       "      <td>YAMAHA RECORDER YRS-24B ID</td>\n",
       "      <td>99.0</td>\n",
       "      <td>GHS</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://melcom.com/catalog/product/view/id/514...</td>\n",
       "      <td>Melcom</td>\n",
       "      <td>Television &amp; Audio</td>\n",
       "      <td>LG LED TV 43 SAT SMT UHD 4K 43UQ7006LB</td>\n",
       "      <td>5799.0</td>\n",
       "      <td>GHS</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>7199.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  source  \\\n",
       "0  https://melcom.com/categories/electronics-appl...  Melcom   \n",
       "1  https://melcom.com/categories/electronics-appl...  Melcom   \n",
       "2  https://melcom.com/categories/electronics-appl...  Melcom   \n",
       "3  https://melcom.com/categories/electronics-appl...  Melcom   \n",
       "4  https://melcom.com/catalog/product/view/id/514...  Melcom   \n",
       "\n",
       "             category                                           name    price  \\\n",
       "0  Television & Audio      YAMAHA FRONT SURROUND SYSTEM BLACK YAS209   6499.0   \n",
       "1  Television & Audio             YAMAHA MUSIC SYNTHESIZER MODX8 B/E  34999.0   \n",
       "2  Television & Audio  YAMAHA DIGITAL KEYBOARD WITH ADAPTOR PSR-F52Y   2099.0   \n",
       "3  Television & Audio                     YAMAHA RECORDER YRS-24B ID     99.0   \n",
       "4  Television & Audio         LG LED TV 43 SAT SMT UHD 4K 43UQ7006LB   5799.0   \n",
       "\n",
       "  currency        date  regular_price  \n",
       "0      GHS  2023-03-15            NaN  \n",
       "1      GHS  2023-03-15            NaN  \n",
       "2      GHS  2023-03-15            NaN  \n",
       "3      GHS  2023-03-15            NaN  \n",
       "4      GHS  2023-03-15         7199.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melcom_catalog_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic websites with Selenium\n",
    "1. Get robot.txt and create exclusion protocol for other calls [webdriver subclass and wrapper for driver.get()]\n",
    "2. Selenium IDE\n",
    "3. Integrate Selenium IDE functions with webdriver subclass\n",
    "4. Data Model\n",
    "5. Scraping\n",
    "6. Save data to CSV\n",
    "\n",
    "\n",
    "More information on Selenium framework: [https://www.selenium.dev/](https://www.selenium.dev/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunisie Booking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and parse robots.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking_root = \"https://www.tunisiebooking.com/\"\n",
    "robots_booking = RobotFileParser(booking_root + \"robots.txt\")\n",
    "robots_booking.read()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selenium IDE\n",
    "\n",
    "This website - like many travel websites - requires to fill a form with travel dates: [https://www.tunisiebooking.com/](https://www.tunisiebooking.com/). We use Selenium IDE to record the website interaction and input the data.  \n",
    "\n",
    "Open Chromium and start a new project in Selenium IDE. Record new test cases:\n",
    "1. Book a room for 2 people in the current month in the default city\n",
    "2. Book a room for 2 people in the next month in the default city\n",
    "3. Book a room for 2 people in the current month in another city\n",
    "\n",
    "From the recorded cases, you can export Python code. This will be the base for our scraping job, and we will add a specific method for each one of those operations into a custom webdriver.Chrome subclass. The main modifications we make:\n",
    "1. Transform some input data (city, checkin day, checkout day) in parameters we can change\n",
    "2. Use our safe_get() method insted than the regular get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "class BookingChrome(webdriver.Chrome):\n",
    "    def safe_get(self, url: str, robots: RobotFileParser):\n",
    "        \"\"\"Load a webpage in the current browser session\n",
    "        if allowed by robots.txt for the specific website\n",
    "        \"\"\"\n",
    "        if robots.can_fetch(self.execute_script('return navigator.userAgent'), url):\n",
    "            self.get(url)\n",
    "\n",
    "    def search_rooms_same_month(self, robots: RobotFileParser, city: str, checkin: int, checkout: int):\n",
    "        self.safe_get(\"https://www.tunisiebooking.com/\", robots)\n",
    "        self.set_window_size(960, 946)\n",
    "        dropdown = self.find_element(By.ID, \"ville_des\")\n",
    "        dropdown.find_element(By.XPATH, f\"//option[. = '{city}']\").click()\n",
    "        element = self.find_element(By.ID, \"ville_des\")\n",
    "        actions = ActionChains(self)\n",
    "        actions.move_to_element(element).click_and_hold().perform()\n",
    "        element = self.find_element(By.ID, \"ville_des\")\n",
    "        actions = ActionChains(self)\n",
    "        actions.move_to_element(element).perform()\n",
    "        element = self.find_element(By.ID, \"ville_des\")\n",
    "        actions = ActionChains(self)\n",
    "        actions.move_to_element(element).release().perform()\n",
    "        self.find_element(By.ID, \"check1\").click()\n",
    "        self.find_element(By.LINK_TEXT, str(checkin)).click()\n",
    "        self.find_element(By.LINK_TEXT, str(checkout)).click()\n",
    "        self.find_element(By.ID, \"boutonr\").click()\n",
    "        self.execute_script(\"window.scrollTo(0,276)\")\n",
    "        # Not all cities may have more results...\n",
    "        try:\n",
    "            self.find_element(By.CSS_SELECTOR, \"#plus_res > img\").click()\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "driver = BookingChrome(service=chromedriver_path, options=opts)\n",
    "driver.implicitly_wait(0)  # The driver will wait up to 0 seconds each time we ask to perform an action or get an element\n",
    "driver.safe_get(booking_root, robots_booking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.search_rooms_same_month(robots_booking, \"Douz\", 25, 27)  # Days are purely random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select the buttons to get more information for each hotel\n",
    "hotels = driver.find_elements(By.XPATH, '//*[@id=\"tailleprix\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We click on the first one to get an idea of the webpage structure\n",
    "hotels[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Demi Pension', 'Petit Dejeuner', 'Pension Complete']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check what are the options for the rate\n",
    "from selenium.webdriver.support.ui import Select \n",
    "\n",
    "[opt.text for opt in Select(driver.find_element(By.XPATH, '//*[@id=\"arrangement\"]')).options]\n",
    "# We will need to select those in a loop to get all the info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could loop over those rate type to see all prices\n",
    "for opt in Select(driver.find_element(By.XPATH, '//*[@id=\"arrangement\"]')).options:\n",
    "    dropdown = driver.find_element(By.XPATH, '//*[@id=\"arrangement\"]')\n",
    "    dropdown.find_element(By.XPATH, \"//option[. = '{}']\".format(opt.text)).click()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the page HTML and parse it with BeautifulSoup\n",
    "page = driver.execute_script(\"return document.body.innerHTML;\")\n",
    "page = BeautifulSoup(page, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sahara Douz Douz'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hotel name\n",
    "page.find(\"div\", {\"class\": \"bloc_titre_hotels\"}).find(\"h2\").get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<i class=\"icon-star-1\" style=\"color:#c9c7c7;font-size: 14px; padding: 0px; margin: -5px; padding-left:8px;\"></i>,\n",
       " <i class=\"icon-star-1\" style=\"color:#c9c7c7;font-size: 14px; padding: 0px; margin: -5px; padding-left:8px;\"></i>,\n",
       " <i class=\"icon-star-1\" style=\"color:#c9c7c7;font-size: 14px; padding: 0px; margin: -5px; padding-left:8px;\"></i>,\n",
       " <i class=\"icon-star-1\" style=\"color:#c9c7c7;font-size: 14px; padding: 0px; margin: -5px; padding-left:8px;\"></i>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hotel star rating\n",
    "page.find(\"div\", {\"class\": \"bloc_titre_hotels\"}).find(\"span\", {\"class\": \"h2styless\"}).find_all(\"i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We just count the stars...this may need changes for half stars (if the website has them)\n",
    "len(page.find(\"div\", {\"class\": \"bloc_titre_hotels\"}).find(\"span\", {\"class\": \"h2styless\"}).find_all(\"i\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<input checked=\"checked\" id=\"choix_formule1_dp_1\" name=\"choix_formule1\" onclick=\"slectform('1','dp','1','1')\" type=\"radio\" value=\"dp@@1@@Chambre  Double Standard@@15@@DLX-G-ROOM-DBL@@652729\"/>,\n",
       " <input id=\"chambre1\" name=\"chambre1\" type=\"hidden\" value=\"\"/>,\n",
       " <input id=\"libelle_chambre1\" name=\"libelle_chambre1\" type=\"hidden\" value=\"Chambre  Double Standard\"/>,\n",
       " <input id=\"choi_chambre1\" name=\"choi_chambre1\" type=\"hidden\" value=\"\"/>,\n",
       " <input id=\"price_dp_1_1\" name=\"price_dp_1_1\" type=\"hidden\" value=\"194\"/>,\n",
       " <input id=\"pricebar_dp_1_1\" name=\"pricebar_dp_1_1\" type=\"hidden\" value=\"0\"/>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Room information and price\n",
    "page.find(\"div\", {\"id\": \"result_par_arrangement\"}).find_all(\"input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chambre  Double Standard'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# Room type\n",
    "page.find(\"div\", {\"id\": \"result_par_arrangement\"}).find(\"input\", id=re.compile(\"^libelle_chambre\")).get(\"value\").strip() # Need to check when multiple rooms are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'194'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Price\n",
    "page.find(\"div\", {\"id\": \"result_par_arrangement\"}).find(\"input\", id=re.compile(\"^price_\")).get(\"value\").strip() # Need to check when multiple rooms are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Disponible'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Availability\n",
    "page.find(\"div\", {\"id\": \"result_par_arrangement\"}).find(\"div\", {\"id\": \"disponible\"}).get_text() # Need to check when multiple rooms are listed and some is not available"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For exploration purposes, we manually select other city/dates to get to a webpage where an hotel has multiple rooms and we parse the new webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually navigate into Chromium to get the new webpage\n",
    "page = driver.execute_script(\"return document.body.innerHTML;\")\n",
    "page = BeautifulSoup(page, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Royal Azur Thalassa Hammamet'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.find(\"div\", {\"class\": \"bloc_titre_hotels\"}).find(\"h2\").get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(page.find(\"div\", {\"class\": \"bloc_titre_hotels\"}).find(\"span\", {\"class\": \"h2styless\"}).find_all(\"i\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Room type: Chambre Double Premium\n",
      "Price: 244\n",
      "Availability:  Disponible\n",
      "--------------------\n",
      "Room type: Chambre Double  Premium Vue Mer\n",
      "Price: 303\n",
      "Availability:  Disponible\n",
      "--------------------\n",
      "Room type: Bungalow Double Vue Mer\n",
      "Price: 377\n",
      "Availability:  Disponible\n",
      "--------------------\n",
      "Room type: Suite Double Premium\n",
      "Price: 392\n",
      "Availability:  Disponible\n",
      "--------------------\n",
      "Room type: Suite Double Business\n",
      "Price: 437\n",
      "Availability:  Disponible\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Each result is inside a div with class line_result. We put them into a list and parse individually\n",
    "room_types = page.find(\"div\", {\"id\": \"result_par_arrangement\"}).find_all(\"div\", {\"class\": \"line_result\"})\n",
    "\n",
    "# We loop across reults and parse them\n",
    "for room in room_types:\n",
    "    print(\"Room type: {}\".format(room.find(\"input\", id=re.compile(\"^libelle_chambre\")).get(\"value\").strip()))\n",
    "    print(\"Price: {}\".format(room.find(\"input\", id=re.compile(\"^price\")).get(\"value\")))\n",
    "    print(\"Availability: {}\".format(room.find(\"div\", {\"id\": \"disponible\"}).get_text()))\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data model\n",
    "\n",
    "The data model in this case is quite different than the one we used for products. We need to consider other characteristics like Hotel star rating, city, room type, etc. The data class below is an example that can be extended according to the specific needs for CPI calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Room(BaseModel):\n",
    "    source: str\n",
    "    hotel_name: str\n",
    "    hotel_stars: str = None\n",
    "    city: str\n",
    "    room_type: str\n",
    "    n_pax: int = 2\n",
    "    n_days: int\n",
    "    checkin: str\n",
    "    checkout: str\n",
    "    price: float\n",
    "    rate_type: str\n",
    "    currency: str\n",
    "    description: str = None\n",
    "    availability: str = None\n",
    "    date: str = date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "class TnBooking(Room):\n",
    "    source: str = \"TunisieBooking\"\n",
    "    currency: str = \"EUR\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping\n",
    "\n",
    "We create some helper function for parsing data, considering that we will need to select the rate type each time in each hotel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_room_rates(page: str, rate_type: str) -> list:\n",
    "    \"\"\"Function to extract the room rates from a webpage\n",
    "    Parameters:\n",
    "        page (str): HTML page with results from room search in an hotel\n",
    "        rate_type (str): type or rate (only breakfast, all, inclusive, etc)\n",
    "\n",
    "    Returns:\n",
    "        list of dictionaries with room prices and information\n",
    "    \"\"\"\n",
    "    page = BeautifulSoup(page, \"html.parser\")\n",
    "    results = []\n",
    "\n",
    "    room_list = page.find(\"div\", {\"id\": \"result_par_arrangement\"}).find_all(\"div\", {\"class\": \"line_result\"})\n",
    "    for room in room_list:\n",
    "        res = {}\n",
    "        res[\"room_type\"] = room.find(\"input\", id=re.compile(\"^libelle_chambre\")).get(\"value\").strip()\n",
    "        res[\"price\"] = room.find(\"input\", id=re.compile(\"^price\")).get(\"value\")\n",
    "        res[\"availability\"] = room.find(\"div\", {\"id\": \"disponible\"}).get_text()\n",
    "        res[\"rate_type\"] = rate_type\n",
    "        results.append(res)\n",
    "\n",
    "    return results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hotel_name_stars(page: str) -> tuple[str, int]:\n",
    "    \"\"\"Function to extract hotel name and star rating from a webpage\n",
    "    Parameters:\n",
    "        page (str): HTML page with results from room search in an hotel\n",
    "\n",
    "    Returns:\n",
    "        hotel_name (str): name of the hotel\n",
    "        hotel_stars (int): star rating of the hotel\n",
    "    \"\"\"\n",
    "    page = BeautifulSoup(page, \"html.parser\")\n",
    "    hotel_name = page.find(\"div\", {\"class\": \"bloc_titre_hotels\"}).find(\"h2\").get_text().strip()\n",
    "    hotel_stars = len(page.find(\"div\", {\"class\": \"bloc_titre_hotels\"}).find(\"span\", {\"class\": \"h2styless\"}).find_all(\"i\"))\n",
    "    return hotel_name, hotel_stars"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a sets of inputs for checkin and checkout dates, and city name. Those variables can be put into production in several different ways:\n",
    "\n",
    "1. Environment variables - see `os.getenv()` [https://docs.python.org/3/library/os.html](https://docs.python.org/3/library/os.html)\n",
    "2. ConfigParser - see [https://docs.python.org/3/library/configparser.html](https://docs.python.org/3/library/configparser.html)\n",
    "3. Command line arguments with argparse [https://docs.python.org/3/library/argparse.html](https://docs.python.org/3/library/argparse.html) or other tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_date = \"2023-03-25\"\n",
    "checkin = int(checkin_date.split(\"-\")[-1])\n",
    "checkout_date = \"2023-03-27\"\n",
    "checkout = int(checkout_date.split(\"-\")[-1])\n",
    "\n",
    "n_days = checkout - checkin     # This is very raw and only suitable for training. \n",
    "                                # It breaks when checkin and chechout are on different months\n",
    "                                # You shold use a timedelta object in production\n",
    "                                # See https://docs.python.org/3/library/datetime.html\n",
    "\n",
    "city = \"Mahdia\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We search for rooms in Mahdia from the 25th to the 27th of current month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.search_rooms_same_month(robots_booking, city, checkin, checkout) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels = driver.find_elements(By.XPATH, '//*[@id=\"tailleprix\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking_data = []\n",
    "\n",
    "for h in hotels:\n",
    "    h.click()\n",
    "    time.sleep(2)\n",
    "    room_options = [opt.text for opt in Select(driver.find_element(By.XPATH, '//*[@id=\"arrangement\"]')).options]\n",
    "    page = driver.execute_script(\"return document.body.innerHTML;\")\n",
    "    hotel_name, hotel_stars = get_hotel_name_stars(page)\n",
    "    for room_opt in room_options:\n",
    "        dropdown = driver.find_element(By.XPATH, '//*[@id=\"arrangement\"]')\n",
    "        dropdown.find_element(By.XPATH, \"//option[. = '{}']\".format(room_opt)).click()\n",
    "        time.sleep(2)\n",
    "        page = driver.execute_script(\"return document.body.innerHTML;\")\n",
    "        res = get_room_rates(page, room_opt)\n",
    "        parsed_res = [\n",
    "            TnBooking(\n",
    "                **r,\n",
    "                hotel_name=hotel_name,\n",
    "                hotel_stars=hotel_stars,\n",
    "                city=city,\n",
    "                n_days=n_days,\n",
    "                checkin=checkin_date,\n",
    "                checkout=checkout_date)\n",
    "            for r in res]\n",
    "        booking_data.extend(parsed_res)\n",
    "    time.sleep(1)\n",
    "    driver.back()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunisiebooking_df = pd.DataFrame([item.dict(exclude_none=True) for item in booking_data])\n",
    "tunisiebooking_df.to_csv(\"tunisiebooking_{}.csv\".format(date.today().strftime(\"%Y-%m-%d\")), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>hotel_name</th>\n",
       "      <th>hotel_stars</th>\n",
       "      <th>city</th>\n",
       "      <th>room_type</th>\n",
       "      <th>n_pax</th>\n",
       "      <th>n_days</th>\n",
       "      <th>checkin</th>\n",
       "      <th>checkout</th>\n",
       "      <th>price</th>\n",
       "      <th>rate_type</th>\n",
       "      <th>currency</th>\n",
       "      <th>availability</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TunisieBooking</td>\n",
       "      <td>Mahdia Palace Thalasso Mahdia</td>\n",
       "      <td>5</td>\n",
       "      <td>Mahdia</td>\n",
       "      <td>Chambre Double Standard</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-25</td>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>149.0</td>\n",
       "      <td>Demi Pension plus</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Disponible</td>\n",
       "      <td>2023-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TunisieBooking</td>\n",
       "      <td>Mahdia Palace Thalasso Mahdia</td>\n",
       "      <td>5</td>\n",
       "      <td>Mahdia</td>\n",
       "      <td>Chambre Double Vue Mer</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-25</td>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>149.0</td>\n",
       "      <td>Demi Pension plus</td>\n",
       "      <td>EUR</td>\n",
       "      <td>3 Disponibles</td>\n",
       "      <td>2023-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TunisieBooking</td>\n",
       "      <td>Mahdia Palace Thalasso Mahdia</td>\n",
       "      <td>5</td>\n",
       "      <td>Mahdia</td>\n",
       "      <td>Chambre Double Standard</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-25</td>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>120.0</td>\n",
       "      <td>Petit Dejeuner</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Disponible</td>\n",
       "      <td>2023-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TunisieBooking</td>\n",
       "      <td>Mahdia Palace Thalasso Mahdia</td>\n",
       "      <td>5</td>\n",
       "      <td>Mahdia</td>\n",
       "      <td>Chambre Double Vue Mer</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-25</td>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>120.0</td>\n",
       "      <td>Petit Dejeuner</td>\n",
       "      <td>EUR</td>\n",
       "      <td>3 Disponibles</td>\n",
       "      <td>2023-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TunisieBooking</td>\n",
       "      <td>Mahdia Beach &amp; Aquapark Mahdia</td>\n",
       "      <td>4</td>\n",
       "      <td>Mahdia</td>\n",
       "      <td>Chambre Double Standard</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-25</td>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>117.0</td>\n",
       "      <td>Demi Pension</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Disponible</td>\n",
       "      <td>2023-03-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                      hotel_name hotel_stars    city  \\\n",
       "0  TunisieBooking   Mahdia Palace Thalasso Mahdia           5  Mahdia   \n",
       "1  TunisieBooking   Mahdia Palace Thalasso Mahdia           5  Mahdia   \n",
       "2  TunisieBooking   Mahdia Palace Thalasso Mahdia           5  Mahdia   \n",
       "3  TunisieBooking   Mahdia Palace Thalasso Mahdia           5  Mahdia   \n",
       "4  TunisieBooking  Mahdia Beach & Aquapark Mahdia           4  Mahdia   \n",
       "\n",
       "                 room_type  n_pax  n_days     checkin    checkout  price  \\\n",
       "0  Chambre Double Standard      2       2  2023-03-25  2023-03-27  149.0   \n",
       "1   Chambre Double Vue Mer      2       2  2023-03-25  2023-03-27  149.0   \n",
       "2  Chambre Double Standard      2       2  2023-03-25  2023-03-27  120.0   \n",
       "3   Chambre Double Vue Mer      2       2  2023-03-25  2023-03-27  120.0   \n",
       "4  Chambre Double Standard      2       2  2023-03-25  2023-03-27  117.0   \n",
       "\n",
       "           rate_type currency   availability        date  \n",
       "0  Demi Pension plus      EUR     Disponible  2023-03-15  \n",
       "1  Demi Pension plus      EUR  3 Disponibles  2023-03-15  \n",
       "2     Petit Dejeuner      EUR     Disponible  2023-03-15  \n",
       "3     Petit Dejeuner      EUR  3 Disponibles  2023-03-15  \n",
       "4       Demi Pension      EUR     Disponible  2023-03-15  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tunisiebooking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always remember to close the browser!\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
